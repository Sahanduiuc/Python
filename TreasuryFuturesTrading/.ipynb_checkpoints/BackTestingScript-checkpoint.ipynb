{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"InputData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def disaggregateInputData(df):\n",
    "    dfPrices = df.iloc[:,0:6]\n",
    "    dfDurations = df.iloc[:,[0,6,7,8,9,10]]\n",
    "    dfOptWeights = df.iloc[:,[0,11,12,13,14,15]]\n",
    "    dfRollingStats = df.loc[:,[\"DateTime\",\"RollingAvg\",\"RollingStd\"]]\n",
    "    \n",
    "    dfPrices.set_index(\"DateTime\",inplace=True)\n",
    "    dfDurations.set_index(\"DateTime\",inplace=True)\n",
    "    dfOptWeights.set_index(\"DateTime\",inplace=True)\n",
    "    dfRollingStats.set_index(\"DateTime\",inplace=True)\n",
    "  \n",
    "    dfPrices.index = pd.to_datetime(dfPrices.index)\n",
    "    dfDurations.index = pd.to_datetime(dfDurations.index)\n",
    "    dfOptWeights.index = pd.to_datetime(dfOptWeights.index)\n",
    "    dfRollingStats.index = pd.to_datetime(dfRollingStats.index)\n",
    "    return (dfPrices,dfDurations,dfOptWeights,dfRollingStats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BackTestingSystem:\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    \n",
    "    def __init__(self, numEquities, pointPrices, tickSizePrices, margins):\n",
    "        self.numEquities = numEquities\n",
    "        if(len(pointPrices) == numEquities):\n",
    "            self.pointPrices = np.array(pointPrices)\n",
    "        else:\n",
    "            print(\"number of equities unmatch: point prices\")\n",
    "        if(len(tickSizePrices) == numEquities):\n",
    "            self.tickSizePrices = np.array(tickSizePrices)\n",
    "        else:\n",
    "            print(\"number of equities unmatch: tickSizes\")\n",
    "        if(len(margins) == numEquities):\n",
    "            self.margins = np.array(margins)\n",
    "        else:\n",
    "            print(\"number of equities unmatch: margins\")\n",
    "    \n",
    "    def set_rollDate(self, rollDate):\n",
    "        self.rollDate = rollDate\n",
    "        \n",
    "    def get_rollDate(self):\n",
    "        return self.rollDate\n",
    "        \n",
    "    def set_exitUpLevel(self, exitUpLevel):\n",
    "        self.exitUpLevel = exitUpLevel\n",
    "        \n",
    "    def set_exitDownLevel(self, exitDownLevel):\n",
    "        self.exitDownLevel\n",
    "        \n",
    "    def set_triggerS(self, triggerS):\n",
    "        self.triggerS = triggerS\n",
    "        \n",
    "    def set_triggerT(self, triggerT):\n",
    "        self.triggerT = triggerT\n",
    "        \n",
    "    def get_marginPrices(self):\n",
    "        return self.margins/self.pointPrices\n",
    "    \n",
    "    def get_tickSizes(self):\n",
    "        return self.pointPrices*tickSizePrices\n",
    "    \n",
    "    def set_AUM(self,AUM):\n",
    "        self.AUM = AUM\n",
    "        \n",
    "    def set_rollingStats(self,dfRollingStats):\n",
    "        self.dfRollingStats = dfRollingStats\n",
    "        self.df = pd.concat([self.df,self.rollingStats],axis=1)\n",
    "                \n",
    "    def set_maxPoistions(self,maxPositions):\n",
    "        self.maxPositions = 30\n",
    "        \n",
    "    def set_percentageInvested(self,pctInvest):\n",
    "        self.percentageInvested = pctInvest\n",
    "    \n",
    "    def set_maxPositions(self,maxPositions):\n",
    "        self.maxPositions = maxPositions\n",
    "    \n",
    "    def input_data(self,dfPrices, dfDurations, dfOptWeights,dfRollingStats):\n",
    "        self.dfPrices = dfPrices\n",
    "        self.dfDurations = dfDurations\n",
    "        self.dfOptWeights = dfOptWeights\n",
    "        self.df = pd.concat([self.dfPrices,self.dfDurations,self.dfOptWeights,dfRollingStats],axis=1)\n",
    "    \n",
    "    # todo: delete   \n",
    "#     def input_whole_data(self,df):\n",
    "#         self.df = df\n",
    "        \n",
    "    def get_df(self):\n",
    "        return self.df    \n",
    "    \n",
    "    def time_delta_365(self,timeDelta):\n",
    "        if(timeDelta.days>0):\n",
    "            return timeDelta.days/365\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        \n",
    "        # todo: preprocessing\n",
    "        print(\"****************************************************************\")\n",
    "        print(\"Start preprocessing...\")\n",
    "        # basic setting\n",
    "        self.marginPrices = self.margins / self.pointPrices\n",
    "        self.maxInitMargin = self.AUM*self.percentageInvested\n",
    "        self.positionInitMargin = self.maxInitMargin/self.maxPositions\n",
    "        self.tickSizes = self.pointPrices*self.tickSizePrices\n",
    "        self.marginPrices = self.margins/self.pointPrices\n",
    "        \n",
    "        # time to maturity\n",
    "        timeDeltas = self.rollDate - self.df.index\n",
    "        self.df['TimeToMaturity'] = timeDeltas\n",
    "        self.df.TimeToMaturity = self.df.TimeToMaturity.apply(self.time_delta_365)\n",
    "        self.timeToMaturity = self.df.TimeToMaturity\n",
    "        print(self.df.head())\n",
    "        # future duration\n",
    "        futureDurationsColumns = [\"dfFutureDuration\"+ dur_str[8:] for dur_str in self.dfDurations.columns]\n",
    "        self.dfFutureDurations = pd.DataFrame(index = self.df.index, columns=futureDurationsColumns)\n",
    "        for index, row in self.dfDurations.iterrows():\n",
    "            self.dfFutureDurations.loc[index,:] = (row - self.df.TimeToMaturity[index]).values\n",
    "\n",
    "        # margin unit\n",
    "#         self.marginUnit = pd.Series(index = self.df.index, name=\"MarginUnit\")\n",
    "#         for index, row in self.dfOptWeights.iterrows():\n",
    "#             self.marginUnit[index] = np.inner(np.abs(row.values), self.marginPrices)\n",
    "        self.marginUnit = self.dfOptWeights.apply(lambda x: np.inner(np.abs(x),self.marginPrices),axis=1)\n",
    "        self.marginUnit.rename(\"MarginUnit\")\n",
    "       \n",
    "        \n",
    "        # national\n",
    "        self.portNotional = self.positionInitMargin/self.marginUnit\n",
    "        self.portNotional.rename(\"PortNotional\",inplace=True)\n",
    "        \n",
    "        # positions\n",
    "        # todo: uncouple columns name\n",
    "        positionsColumns = [\"dfPosition\"+ dur_str[8:] for dur_str in self.dfDurations.columns]\n",
    "        self.dfPositions = pd.DataFrame(index = self.df.index, columns=positionsColumns)\n",
    "        for index, row in self.dfOptWeights.iterrows():\n",
    "            self.dfPositions.loc[index,:] = row.values*self.portNotional[index]/self.pointPrices\n",
    "        # tick size\n",
    "        self.portTickSize = self.dfPositions.apply(lambda x: np.inner(np.abs(x),self.tickSizes),axis=1)\n",
    "        self.portTickSize.rename(\"PortTickSize\",inplace=True)\n",
    "        \n",
    "        # current price\n",
    "        self.portPrice = pd.Series(index=self.df.index,name=\"PortPrice\")\n",
    "        for idx in self.df.index:\n",
    "            self.portPrice[idx] = np.inner(self.dfPrices.loc[idx,:],self.dfOptWeights.loc[idx,:])\n",
    "        \n",
    "        # tick size price\n",
    "        self.portTickSizePrice = pd.Series(index=self.df.index,name=\"PortTickSizePrice\")\n",
    "        for idx in self.df.index:\n",
    "            self.portTickSizePrice[idx] = self.portTickSize[idx]/self.portNotional[idx]\n",
    "        \n",
    "        # z-score\n",
    "        self.ZScore = pd.Series(index=self.df.index,name=\"ZScore\")\n",
    "        for idx in self.df.index:\n",
    "            self.ZScore[idx] = (self.portPrice[idx]-self.df.RollingAvg[idx])/self.df.RollingStd[idx]\n",
    "\n",
    "        # t-score\n",
    "        self.TScore = pd.Series(index=self.df.index,name=\"TScore\")\n",
    "        for idx in self.df.index:\n",
    "            self.TScore[idx] = (self.portPrice[idx]-self.df.RollingAvg[idx])/self.portTickSizePrice[idx]\n",
    "    \n",
    "        # concat all results\n",
    "        self.df = pd.concat([self.df,self.dfFutureDurations,self.marginUnit,self.portNotional,\n",
    "                             self.dfPositions,self.portTickSize, self.portPrice,self.portTickSizePrice,\n",
    "                            self.ZScore,self.TScore],axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"Preprocessing finished!\")\n",
    "        print(\"****************************************************************\")\n",
    "        return self.df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "Start preprocessing...\n",
      "                        PriceTU     PriceFV     PriceTY    PriceUS    PriceUB  \\\n",
      "DateTime                                                                        \n",
      "2017-01-02 19:00:00  108.296875  117.523438  124.046875  150.21875  159.59375   \n",
      "2017-01-02 20:00:00  108.296875  117.539062  124.078125  150.31250  159.75000   \n",
      "2017-01-02 21:00:00  108.304688  117.554688  124.093750  150.34375  159.75000   \n",
      "2017-01-02 22:00:00  108.312500  117.578125  124.109375  150.34375  159.78125   \n",
      "2017-01-02 23:00:00  108.312500  117.585938  124.125000  150.43750  159.90625   \n",
      "\n",
      "                     DurationTU  DurationFV  DurationTY  DurationUS  \\\n",
      "DateTime                                                              \n",
      "2017-01-02 19:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 20:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 21:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 22:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 23:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "\n",
      "                     DurationUB  OptWeightTU  OptWeightFV  OptWeightTY  \\\n",
      "DateTime                                                                 \n",
      "2017-01-02 19:00:00   17.468457     0.239421     0.176399    -0.135898   \n",
      "2017-01-02 20:00:00   17.468457     0.205643     0.221380    -0.175470   \n",
      "2017-01-02 21:00:00   17.468457     0.306894     0.095349    -0.074645   \n",
      "2017-01-02 22:00:00   17.468457     0.352609    -0.105151     0.063064   \n",
      "2017-01-02 23:00:00   17.468457     0.315661    -0.160763     0.110985   \n",
      "\n",
      "                     OptWeightUS  OptWeightUB  RollingAvg  RollingStd  \\\n",
      "DateTime                                                                \n",
      "2017-01-02 19:00:00    -0.263656     0.184626   19.729368    0.027984   \n",
      "2017-01-02 20:00:00    -0.231472     0.166035   18.312467    0.026713   \n",
      "2017-01-02 21:00:00    -0.310858     0.212253   22.434865    0.031605   \n",
      "2017-01-02 22:00:00    -0.288999     0.190178   20.655034    0.028392   \n",
      "2017-01-02 23:00:00    -0.251162     0.161430   17.145529    0.023511   \n",
      "\n",
      "                     TimeToMaturity  \n",
      "DateTime                             \n",
      "2017-01-02 19:00:00        0.156164  \n",
      "2017-01-02 20:00:00        0.156164  \n",
      "2017-01-02 21:00:00        0.156164  \n",
      "2017-01-02 22:00:00        0.156164  \n",
      "2017-01-02 23:00:00        0.156164  \n",
      "Preprocessing finished!\n",
      "****************************************************************\n",
      "                        PriceTU     PriceFV     PriceTY    PriceUS    PriceUB  \\\n",
      "DateTime                                                                        \n",
      "2017-01-02 19:00:00  108.296875  117.523438  124.046875  150.21875  159.59375   \n",
      "2017-01-02 20:00:00  108.296875  117.539062  124.078125  150.31250  159.75000   \n",
      "2017-01-02 21:00:00  108.304688  117.554688  124.093750  150.34375  159.75000   \n",
      "2017-01-02 22:00:00  108.312500  117.578125  124.109375  150.34375  159.78125   \n",
      "2017-01-02 23:00:00  108.312500  117.585938  124.125000  150.43750  159.90625   \n",
      "\n",
      "                     DurationTU  DurationFV  DurationTY  DurationUS  \\\n",
      "DateTime                                                              \n",
      "2017-01-02 19:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 20:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 21:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 22:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "2017-01-02 23:00:00    1.957515     4.24503    6.222844    13.85058   \n",
      "\n",
      "                     DurationUB    ...     dfPositionTU  dfPositionFV  \\\n",
      "DateTime                           ...                                  \n",
      "2017-01-02 19:00:00   17.468457    ...          6.93012       10.2118   \n",
      "2017-01-02 20:00:00   17.468457    ...          6.25113        13.459   \n",
      "2017-01-02 21:00:00   17.468457    ...          8.34136       5.18317   \n",
      "2017-01-02 22:00:00   17.468457    ...          10.3791      -6.19023   \n",
      "2017-01-02 23:00:00   17.468457    ...          9.98825      -10.1738   \n",
      "\n",
      "                     dfPositionTY  dfPositionUS  dfPositionUB  PortTickSize  \\\n",
      "DateTime                                                                      \n",
      "2017-01-02 19:00:00      -7.86725      -15.2632       10.6881   1121.968097   \n",
      "2017-01-02 20:00:00      -10.6679      -14.0725       10.0942   1124.718872   \n",
      "2017-01-02 21:00:00      -4.05767      -16.8982        11.538   1122.860139   \n",
      "2017-01-02 22:00:00       3.71258      -17.0134       11.1958   1150.081270   \n",
      "2017-01-02 23:00:00       7.02362      -15.8947       10.2161   1161.254815   \n",
      "\n",
      "                     PortPrice  PortTickSizePrice    ZScore    TScore  \n",
      "DateTime                                                               \n",
      "2017-01-02 19:00:00  19.660852           0.019381 -2.448433 -3.535253  \n",
      "2017-01-02 20:00:00  18.250280           0.018500 -2.327933 -3.361486  \n",
      "2017-01-02 21:00:00  22.355819           0.020656 -2.501032 -3.826729  \n",
      "2017-01-02 22:00:00  20.593131           0.019536 -2.180324 -3.168695  \n",
      "2017-01-02 23:00:00  17.092052           0.018350 -2.274573 -2.914337  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "(dfPrices,dfDurations,dfOptWeights,dfRollingStats) = disaggregateInputData(df)\n",
    "\n",
    "# print(rollingStats.head())\n",
    "pointPrices = [2000,1000,1000,1000,1000]\n",
    "tickSizePrices = [1/128,1/128,1/64,1/32,1/32]\n",
    "margins = [380,625,1300,2700,3700]\n",
    "# hyper parameteres\n",
    "numEquities = 5\n",
    "AUM = 10000000\n",
    "\n",
    "# model parameters\n",
    "rollDate = datetime(2017,3,1)\n",
    "triggerS = 2\n",
    "triggerT = 5\n",
    "exitUpLevel = 2\n",
    "exitDownLevel = 20\n",
    "pctInvested = 0.3\n",
    "maxPositions = 30\n",
    "\n",
    "# plug in\n",
    "# HyperParameteres\n",
    "backTesting = BackTestingSystem(numEquities,pointPrices,tickSizePrices,margins)\n",
    "# Model Parameters\n",
    "backTesting.set_AUM(AUM)\n",
    "backTesting.set_percentageInvested(pctInvested)\n",
    "backTesting.set_maxPoistions(maxPositions)\n",
    "backTesting.set_rollDate(rollDate)\n",
    "backTesting.set_triggerS(triggerS)\n",
    "backTesting.set_triggerT(triggerT)\n",
    "# History Data\n",
    "backTesting.input_data(dfPrices,dfDurations,dfOptWeights,dfRollingStats)\n",
    "\n",
    "# pre-processing\n",
    "df2 = backTesting.preprocessing()\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
